{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7385d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import scipy.io\n",
    "from scipy.io import loadmat\n",
    "from scipy import stats\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import sklearn.tree\n",
    "import random\n",
    "from PIL import Image\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75b6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_FILE = \"dataset/raw_power_data_alu32.csv\"\n",
    "df = pd.read_csv(RAW_FILE)\n",
    "\n",
    "y = df[\"switching_power\"].to_numpy().reshape(-1, 1)\n",
    "\n",
    "df_X = df.drop([\"switching_power\"], axis=1)\n",
    "features = list(df_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff5f5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALU_SLTU 0.27354106779661014\n",
      "ALU_COPY_B 0.2744712373831775\n",
      "ALU_SLT 0.2780842668067227\n",
      "ALU_AND 0.26880270291262137\n",
      "ALU_SLL 0.2920164632768361\n",
      "ALU_SRL 0.2765932798434442\n",
      "ALU_XXX 0.29108913243761997\n",
      "ALU_XOR 0.2761328968871595\n",
      "ALU_ADD 0.2637254732510288\n",
      "ALU_OR 0.2876492095588235\n",
      "ALU_SRA 0.2727502450592886\n",
      "ALU_SUB 0.26917280855397147\n"
     ]
    }
   ],
   "source": [
    "for code in df['opcode'].unique():\n",
    "    print(code, df[df['opcode'] == code]['switching_power'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bcc85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating train and validation sets\n",
    "RAND_SEED = 251289\n",
    "DATA_FILE = \"dataset/processed_power_data_alu32.mat\"\n",
    "\n",
    "def load_and_split_dataset(file=DATA_FILE, validation_size=0.2):\n",
    "    '''\n",
    "        Save .mat file contain the dataset ready for training/validation/testing\n",
    "        One can read the .mat file using scipy.io.loadmat(<file_name>)\n",
    "    '''\n",
    "    data = loadmat(file)\n",
    "    features = data['features']\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(data['X'], data['y'], test_size=validation_size, shuffle=True, random_state=RAND_SEED)\n",
    "\n",
    "    return X_train, X_validation, y_train, y_validation, features\n",
    "\n",
    "X_train, X_validation, y_train, y_validation, features = load_and_split_dataset()\n",
    "# y_train *= 1e6 #(uW)\n",
    "# y_validation *= 1e6 #(uW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57093e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 1., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 1., 0., ..., 1., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "093d481f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoang\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE for DecisionTree:  7.848927067018361\n"
     ]
    }
   ],
   "source": [
    "#Construct the DecisionTree and Train\n",
    "# regressor = DecisionTreeRegressor(random_state=RAND_SEED) \n",
    "# use X_train, augment by adding another column, that column is output of least square (preds?) concatenate\n",
    "regressor = GradientBoostingRegressor(random_state=RAND_SEED) \n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "#Construct the Predictions\n",
    "y_pred = regressor.predict(X_validation)\n",
    "# y_pred = y_train.mean()\n",
    "# print(y_pred)\n",
    "# NRMSE - 1/(y_max - y_min) * np.sqrt(np.sum((y - y^hat)**2)/n)\n",
    "y_max = max(y_validation)[0]\n",
    "y_min = min(y_validation)[0]\n",
    "NRMSE = 1/(y_max - y_min) * np.sqrt(np.sum((y_validation - y_pred)**2)/len(y_validation))\n",
    "print(\"NRMSE for DecisionTree: \", NRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84634937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "depths = np.arange(1, 11)\n",
    "feature_arr = np.arange(1, X_train.shape[1] + 1)\n",
    "\n",
    "bestNRMSE = np.inf\n",
    "best_y_pred = []\n",
    "bestdepth = -1\n",
    "bestfeature = -1\n",
    "for feature in feature_arr:\n",
    "    print(str(feature) + \" Features Subset Selection\")\n",
    "    for depth in depths:\n",
    "        #Construct the RandomForest and Train\n",
    "        regressor = RandomForestRegressor(max_depth=depth, max_features = feature, random_state=RAND_SEED)\n",
    "        regressor.fit(X_train, y_train.ravel())\n",
    "        #Construct the Predictions\n",
    "        y_pred = regressor.predict(X_validation)\n",
    "        #NRMSE\n",
    "        NRMSE = 1/(y_max - y_min) * np.sqrt(np.sum((y_validation - y_pred)**2)/len(y_validation))\n",
    "        if (NRMSE < bestNRMSE):\n",
    "            bestNRMSE = NRMSE\n",
    "            bestdepth = depth\n",
    "            bestfeature = feature\n",
    "            best_y_pred = y_pred\n",
    "        #print(\"     NRMSE for RandomForest with depth \" + str(depth) + \": \" + str(NRMSE))\n",
    "print(\"Best NRMSE: \" + str(bestNRMSE))\n",
    "print(\"Best Depth:\" + str(bestdepth))\n",
    "print(\"Best Subset Feature Num:\" + str(bestfeature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc612ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02804836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_validation.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f453ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other algorithms\n",
    "# neural net? \n",
    "\n",
    "# produce plots show how we do validation\n",
    "# course staff should understand what we did, performance of all opcodes, inputs, \n",
    "# training plots, condition number of matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
